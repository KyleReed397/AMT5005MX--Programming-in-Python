{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyxI4sRI2j9YA1+BF7pyPO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KyleReed397/AMT5005MX--Programming-in-Python/blob/main/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PePoRAgILPG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_data(data_folder):\n",
        "    \"\"\"Load audio files from dataset\"\"\"\n",
        "    genres = ['blues', 'classical', 'country', 'disco', 'hiphop',\n",
        "              'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "\n",
        "    audio_files = []\n",
        "    labels = []\n",
        "\n",
        "    for genre_idx, genre in enumerate(genres):\n",
        "        genre_folder = os.path.join(data_folder, genre)\n",
        "        if os.path.exists(genre_folder):\n",
        "            wav_files = [f for f in os.listdir(genre_folder)\n",
        "                        if f.endswith('.wav') or f.endswith('.au')]\n",
        "            audio_files.extend([os.path.join(genre_folder, f) for f in wav_files])\n",
        "            labels.extend([genre_idx] * len(wav_files))\n",
        "\n",
        "    return audio_files, labels, genres\n",
        "\n",
        "def extract_features(audio_path):\n",
        "    \"\"\"Extract features from audio file\"\"\"\n",
        "    try:\n",
        "        # Load exactly 30 seconds of audio\n",
        "        audio, sr = librosa.load(audio_path, sr=22050, duration=30)\n",
        "\n",
        "        # fix for audio length\n",
        "        target_length = 22050 * 30  # 30 seconds at 22050 Hz\n",
        "        if len(audio) < target_length:\n",
        "            audio = np.pad(audio, (0, target_length - len(audio)))\n",
        "        else:\n",
        "            audio = audio[:target_length]\n",
        "\n",
        "        # Extract mel-spectrogram withparameters\n",
        "        mel_spec = librosa.feature.melspectrogram(\n",
        "            y=audio, sr=sr, n_mels=128, hop_length=512, n_fft=2048)\n",
        "\n",
        "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "        mel_spec_db = (mel_spec_db - np.mean(mel_spec_db)) / (np.std(mel_spec_db) + 1e-8)\n",
        "\n",
        "        return mel_spec_db\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "        return np.zeros((128, 1293))\n",
        "\n",
        "class MusicCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MusicCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128 * 16 * 161, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "def train_model(data_folder, max_files=5):\n",
        "    \"\"\"Train the model\"\"\"\n",
        "    print(\"Loading data...\")\n",
        "    audio_files, labels, genres = load_data(data_folder)\n",
        "\n",
        "    # Limit files to fasten process\n",
        "    if max_files:\n",
        "        limited_files = []\n",
        "        limited_labels = []\n",
        "        for genre_idx in range(10):\n",
        "            genre_files = [f for f, l in zip(audio_files, labels) if l == genre_idx]\n",
        "            genre_files = genre_files[:max_files]\n",
        "            limited_files.extend(genre_files)\n",
        "            limited_labels.extend([genre_idx] * len(genre_files))\n",
        "        audio_files, labels = limited_files, limited_labels\n",
        "\n",
        "    print(f\"Processing {len(audio_files)} files...\")\n",
        "\n",
        "    # Extract features\n",
        "    features_list = []\n",
        "    for file_path in tqdm(audio_files):\n",
        "        features = extract_features(file_path)\n",
        "        features_list.append(features)\n",
        "\n",
        "    X = np.array(features_list)\n",
        "    y = np.array(labels)\n",
        "    X = np.expand_dims(X, axis=1)\n",
        "\n",
        "    # Split data\n",
        "    indices = np.arange(len(X))\n",
        "    np.random.shuffle(indices)\n",
        "    train_size = int(0.8 * len(X))\n",
        "    train_idx = indices[:train_size]\n",
        "    test_idx = indices[train_size:]\n",
        "\n",
        "    X_train, y_train = X[train_idx], y[train_idx]\n",
        "    X_test, y_test = X[test_idx], y[test_idx]\n",
        "\n",
        "    print(f\"Training on {len(X_train)} samples...\")\n",
        "\n",
        "    # Setup model\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = MusicCNN().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    X_train = torch.FloatTensor(X_train).to(device)\n",
        "    y_train = torch.LongTensor(y_train).to(device)\n",
        "\n",
        "    # Train\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 2 == 0:\n",
        "            print(f'Epoch {epoch+1}/10, Loss: {loss.item():.4f}')\n",
        "\n",
        "    # Test\n",
        "    X_test = torch.FloatTensor(X_test).to(device)\n",
        "    y_test = torch.LongTensor(y_test).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_test)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        accuracy = (predicted == y_test).float().mean().item()\n",
        "\n",
        "    print(f'Accuracy: {accuracy:.1%}')\n",
        "\n",
        "    return model, genres\n",
        "\n",
        "def predict_song(model, audio_path, genres):\n",
        "    \"\"\"Predict genre of a song\"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    features = extract_features(audio_path)\n",
        "    features_tensor = torch.FloatTensor(features).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(features_tensor)\n",
        "        probabilities = torch.softmax(output, dim=1)[0]\n",
        "        predicted_idx = torch.argmax(output, dim=1)[0].item()\n",
        "\n",
        "    return {\n",
        "        'genre': genres[predicted_idx],\n",
        "        'confidence': probabilities[predicted_idx].item()\n",
        "    }\n",
        "\n",
        "# Usage\n",
        "def run_classification(data_path, song_path):\n",
        "    \"\"\"Complete workflow: train and predict\"\"\"\n",
        "    # Train model\n",
        "    model, genres = train_model(data_path)\n",
        "\n",
        "    # Predict song\n",
        "    result = predict_song(model, song_path, genres)\n",
        "    print(f\"\\nPredicted genre: {result['genre']}\")\n",
        "    print(f\"Confidence: {result['confidence']:.1%}\")\n",
        "\n",
        "    return model, genres\n",
        "\n",
        "# Example usage:\n",
        "# model, genres = train_model(\"/path/to/genres_original\")\n",
        "# result = predict_song(model, \"/path/to/song.wav\", genres)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hugZM21WIhPu",
        "outputId": "6ef6122b-b51f-4675-f4ba-a870655cfa79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your paths here\n",
        "data_path = \"/content/drive/MyDrive/DATASET/genres_original\"\n",
        "song_path = \"/content/drive/MyDrive/u dont understand ORIGINAL BEFORE NEW LYRICS latest.wav\""
      ],
      "metadata": {
        "id": "vGNH7E2HKDwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First train the model\n",
        "model, genres = train_model(data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY7FIDK5KV4i",
        "outputId": "b7ebcf61-6778-4dda-a945-a0f802dfe740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Processing 50 files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:03<00:00, 14.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 40 samples...\n",
            "Epoch 1/10, Loss: 2.3003\n",
            "Epoch 3/10, Loss: 9.3885\n",
            "Epoch 5/10, Loss: 2.5232\n",
            "Epoch 7/10, Loss: 2.0593\n",
            "Epoch 9/10, Loss: 1.3980\n",
            "Accuracy: 50.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = predict_song(model, song_path, genres)\n",
        "print(f\"Predicted genre: {result['genre']}\")\n",
        "print(f\"Confidence: {result['confidence']:.1%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b7UFWeaKzEU",
        "outputId": "0dcffc33-570e-4a4e-d1cb-78913db45396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted genre: pop\n",
            "Confidence: 23.6%\n"
          ]
        }
      ]
    }
  ]
}